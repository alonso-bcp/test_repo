{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53f34f98-55c7-43a7-9dc1-29cd09946c8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.append('/Workspace/Users/luisfdiaz@bcp.com.pe/Modulo de Seguimiento/')\n",
    "\n",
    "import SegScore as rmm\n",
    "importlib.reload(rmm)\n",
    "\n",
    "# Librerias y fuciones generales\n",
    "from pyspark.sql.functions import date_format, expr, to_date, date_sub, add_months, col, when, coalesce, trim, broadcast, avg, max, min, lit, concat, window, round as colround, upper, abs as sparkabs,greatest\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import StorageLevel\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Mostrar los duplicados\n",
    "def print_res(sparkf_df):\n",
    "  import pandas as pd\n",
    "  pd.set_option('display.max_rows', None)\n",
    "  pd.set_option('display.max_columns', None)\n",
    "  pd_spark_df = sparkf_df.toPandas()\n",
    " \n",
    "  return pd_spark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9a63419-94d8-423e-abdc-b4abad731534",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Base de seguimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91b1005f-d61e-4b33-83b3-e373b216932c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, expr, to_date, date_sub, add_months, col, when, coalesce, trim\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Omitir todas las advertencias\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Parámetros de guardado\n",
    "vUsuario = 'T39290'\n",
    "vP = 'Vjqgqg$9171#'\n",
    "vNumReg = 10000000\n",
    "vStorage = \"adlscu1lhclbackp05\"\n",
    "vRutaEdvDestino = \"bcp-edv-fabseg/T39290/Bases DWH/Base Applicant Hipotecario\"\n",
    "vContainer = vRutaEdvDestino.split(\"/\", 1)[0]\n",
    "vRutaEDV = vRutaEdvDestino[len(vContainer) : len(vRutaEdvDestino)]\n",
    "vQueryOrigen = \"SELECT * FROM S35105.HM_MTZ_ADM_HIPOTECARIO_DRIVER WHERE CODMES >= 201701\"\n",
    "\n",
    "try:\n",
    "    # Lectura de la base de hipotecario\n",
    "    base_app_veh = (\n",
    "        spark.read.format(\"jdbc\")\n",
    "        .option(\"url\", \"jdbc:oracle:thin:@PRODREG.credito.bcp.com.pe:1521/BCPDW3\")       \n",
    "        .option(\"dbtable\", \"(SELECT ROWNUM as R, t.* FROM (\"+vQueryOrigen+\") t ) mitabla\")\n",
    "        .option(\"fetchSize\",100000) \n",
    "        .option(\"partitionColumn\", \"R\")\n",
    "        .option(\"lowerBound\", \"1\")\n",
    "        .option(\"upperBound\", vNumReg)\n",
    "        .option(\"numPartitions\", \"50\")\n",
    "        .option(\"user\", vUsuario)\n",
    "        .option(\"password\", vP)\n",
    "        .option(\"driver\", \"oracle.jdbc.driver.OracleDriver\")\n",
    "        .option(\"oracle.jdbc.timezoneAsRegion\", \"false\")\n",
    "        .option(\"oracle.jdbc.defaultCharSet\", \"UTF-8\")\n",
    "        .load()\n",
    "    )\n",
    "    print(f\"Conexión exitosa: consulta '{vQueryOrigen}' leida correctamente.\")\n",
    "\n",
    "    # Guardar el DataFrame en un contenedor de Azure Storage Account\n",
    "    base_app_veh.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://\"+vContainer+\"@\"+vStorage+\".dfs.core.windows.net\"+vRutaEDV)\n",
    "\n",
    "    spark.sql(\n",
    "    '''\n",
    "        DROP TABLE IF EXISTS catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_BASE_APP_HIP\n",
    "    '''\n",
    "    )\n",
    "    spark.sql('''\n",
    "        CREATE TABLE \n",
    "            catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_BASE_APP_HIP\n",
    "        USING DELTA LOCATION \n",
    "            'abfss://bcp-edv-fabseg@adlscu1lhclbackp05.dfs.core.windows.net/T39290/Bases DWH/Base Applicant Hipotecario'\n",
    "    '''\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Conexión fallida: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce045dd6-0169-4e7d-88f1-122f252f102f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_app_veh.agg(F.max(\"CODMES\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eb00e30-64c3-4771-ab78-f260b4043352",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bases Espejo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51cdc7a2-af67-46b7-80c1-c37d7240a15c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hip. Trad y Pyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffb4af24-d320-4041-b03f-b6c2442bf801",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install pyreadstat\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Puntuaciones historicas\n",
    "espejo_hist = spark.table('catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_MM_APPSCORE_HIP_TRD_202504')\n",
    "\n",
    "folder_path = '/Workspace/Users/luisfdiaz@bcp.com.pe/Seguimiento/Applicant Hipotecario/Inputs/Base Espejo Hip. Trad - Pyme'\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.sas7bdat')]\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df, meta = pyreadstat.read_sas7bdat(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Unir todos los DataFrames\n",
    "espejo1 = pd.concat(dfs, ignore_index=True)\n",
    "espejo1 = espejo1.fillna('')\n",
    "espejo = spark.createDataFrame(espejo1)\n",
    "\n",
    "# Uniendo puntuaciones\n",
    "espejo_total = espejo_hist.unionByName(espejo, allowMissingColumns=True)\n",
    "\n",
    "espejo_total.createOrReplaceTempView(\"espejo\")\n",
    "spark.sql(\n",
    "    '''\n",
    "    CREATE OR REPLACE TABLE\n",
    "        catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_mm_appscore_hip_trad\n",
    "    USING DELTA LOCATION \n",
    "        'abfss://bcp-edv-fabseg@adlscu1lhclbackp05.dfs.core.windows.net/T39290/Seguimiento/02_Applicant_Hipotecario/mm_appscpre_hip_trad'\n",
    "    AS SELECT * FROM espejo\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Conteo registros\n",
    "espejo_sql = spark.table('catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_mm_appscore_hip_trad') \n",
    "info = espejo_sql.filter(\"CODMES_SOLICITUD >= 202201\").groupBy(\"CODMES_SOLICITUD\").agg(F.count(\"*\").alias(\"REGISTROS\")).orderBy(\"CODMES_SOLICITUD\")\n",
    "print_res(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97fd0f9f-8a43-4cde-a2c1-a5bac2f04333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hip. Ahlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7beef135-5f1a-4f93-a8b6-0d19f708bc85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Puntuaciones historicas\n",
    "espejo_hist = spark.table('catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_MM_APPSCORE_HIP_AHL_202504')\n",
    "\n",
    "folder_path = '/Workspace/Users/luisfdiaz@bcp.com.pe/Seguimiento/Applicant Hipotecario/Inputs/Base Espejo Hip. Ahlo'\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.sas7bdat')]\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df, meta = pyreadstat.read_sas7bdat(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Unir todos los DataFrames\n",
    "espejo1 = pd.concat(dfs, ignore_index=True)\n",
    "espejo = spark.createDataFrame(espejo1)\n",
    "\n",
    "# Uniendo puntuaciones\n",
    "espejo_total = espejo_hist.unionByName(espejo, allowMissingColumns=True)\n",
    "\n",
    "espejo_total.createOrReplaceTempView(\"espejo\")\n",
    "spark.sql(\n",
    "    '''\n",
    "    CREATE OR REPLACE TABLE\n",
    "        catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_mm_appscore_hip_ahlo\n",
    "    USING DELTA LOCATION \n",
    "        'abfss://bcp-edv-fabseg@adlscu1lhclbackp05.dfs.core.windows.net/T39290/Seguimiento/02_Applicant_Hipotecario/mm_appscore_hip_ahlo'\n",
    "    AS SELECT * FROM espejo\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Conteo registros\n",
    "espejo_sql = spark.table('catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_mm_appscore_hip_ahlo') \n",
    "info = espejo_sql.filter(\"CODMES_SOLICITUD >= 202201\").groupBy(\"CODMES_SOLICITUD\").agg(F.count(\"*\").alias(\"REGISTROS\")).orderBy(\"CODMES_SOLICITUD\")\n",
    "print_res(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad691e5-cddf-4004-b50b-b440cae42a7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Gahi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21ab8782-ab98-46e3-8d4b-a758cab5221e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_espejo_ant=spark.sql(\"select distinct * from catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_MM_APPSCORE_GARANTIAHIP_202503\")\n",
    "base_espejo_m=spark.sql(\"select distinct * from catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_MM_APPSCORE_GARANTIAHIP_202504\")\n",
    "espejo_hist = base_espejo_ant.unionByName(base_espejo_m)\n",
    "\n",
    "folder_path = '/Workspace/Users/luisfdiaz@bcp.com.pe/Seguimiento/Applicant Hipotecario/Inputs/Base Espejo GAHI'\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.sas7bdat')]\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df, meta = pyreadstat.read_sas7bdat(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Unir todos los DataFrames\n",
    "espejo1 = pd.concat(dfs, ignore_index=True)\n",
    "espejo = spark.createDataFrame(espejo1)\n",
    "\n",
    "# Uniendo puntuaciones\n",
    "espejo_total = espejo_hist.unionByName(espejo, allowMissingColumns=True)\n",
    "\n",
    "espejo_total.createOrReplaceTempView(\"espejo\")\n",
    "spark.sql(\n",
    "    '''\n",
    "    CREATE OR REPLACE TABLE\n",
    "        catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_mm_appscore_gahi\n",
    "    USING DELTA LOCATION \n",
    "        'abfss://bcp-edv-fabseg@adlscu1lhclbackp05.dfs.core.windows.net/T39290/Seguimiento/02_Applicant_Hipotecario/mm_appscore_gahi'\n",
    "    AS SELECT * FROM espejo\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Conteo registros\n",
    "espejo_sql = spark.table('catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_mm_appscore_gahi') \n",
    "info = espejo_sql.filter(\"CODMES_SOLICITUD >= 202201\").groupBy(\"CODMES_SOLICITUD\").agg(F.count(\"*\").alias(\"REGISTROS\")).orderBy(\"CODMES_SOLICITUD\")\n",
    "print_res(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7da0040-f76b-4649-af49-673ac1777d93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Puntuaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a564513d-ee24-44b0-93f7-b11fb1120d26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "069ead8c-e28e-4482-845c-f2893007f61d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hip. Trad y Pyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d34d5e3-9376-470e-94bd-04648ff5dd93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Puntuaciones historicas\n",
    "espejo_hist = spark.table('catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_HM_ADM_HIP_TRADPYME_2Q24_202504')\n",
    "\n",
    "folder_path = '/Workspace/Users/luisfdiaz@bcp.com.pe/Seguimiento/Applicant Hipotecario/Inputs/Puntuación Táctica Hip. Trad - Pyme'\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.sas7bdat')]\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df, meta = pyreadstat.read_sas7bdat(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Unir todos los DataFrames\n",
    "espejo1 = pd.concat(dfs, ignore_index=True)\n",
    "espejo = spark.createDataFrame(espejo1)\n",
    "\n",
    "# Uniendo puntuaciones\n",
    "espejo_total = espejo_hist.unionByName(espejo, allowMissingColumns=True)\n",
    "\n",
    "espejo_total.createOrReplaceTempView(\"espejo\")\n",
    "spark.sql(\n",
    "    '''\n",
    "    CREATE OR REPLACE TABLE\n",
    "        catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_hm_adm_hip_trad_score\n",
    "    USING DELTA LOCATION \n",
    "        'abfss://bcp-edv-fabseg@adlscu1lhclbackp05.dfs.core.windows.net/T39290/Seguimiento/02_Applicant_Hipotecario/hm_adm_hip_trad_score'\n",
    "    AS SELECT * FROM espejo\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Conteo registros\n",
    "espejo_sql = spark.table('catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_hm_adm_hip_trad_score') \n",
    "info = espejo_sql.filter(\"CODMES >= 202201\").groupBy(\"CODMES\").agg(F.count(\"*\").alias(\"REGISTROS\")).orderBy(\"CODMES\")\n",
    "print_res(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f453853d-ec6b-4b16-b752-f35aef71b8f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hip. Ahlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c8fdadb-b1bf-40c9-9fb6-dd45f7c9ad01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install pyreadstat\n",
    "\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Puntuaciones historicas\n",
    "espejo_hist = spark.table('catalog_lhcl_prod_bcp.bcp_edv_fabseg.T45988_HM_ADM_HIP_AHLO_Q424_202504')\n",
    "\n",
    "folder_path = '/Workspace/Users/luisfdiaz@bcp.com.pe/Seguimiento/Applicant Hipotecario/Inputs/Puntuación Táctica Hip. Ahlo'\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.sas7bdat')]\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df, meta = pyreadstat.read_sas7bdat(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Unir todos los DataFrames\n",
    "espejo1 = pd.concat(dfs, ignore_index=True)\n",
    "espejo1 = espejo1.fillna('')\n",
    "espejo = spark.createDataFrame(espejo1)\n",
    "\n",
    "# Uniendo puntuaciones\n",
    "espejo_total = espejo_hist.unionByName(espejo, allowMissingColumns=True)\n",
    "\n",
    "espejo_total.createOrReplaceTempView(\"espejo\")\n",
    "spark.sql(\n",
    "    '''\n",
    "    CREATE OR REPLACE TABLE\n",
    "        catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_hm_adm_hip_ahlo_score\n",
    "    USING DELTA LOCATION \n",
    "        'abfss://bcp-edv-fabseg@adlscu1lhclbackp05.dfs.core.windows.net/T39290/Seguimiento/02_Applicant_Hipotecario/hm_adm_hip_ahlo_score'\n",
    "    AS SELECT * FROM espejo\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Conteo registros\n",
    "espejo_sql = spark.table('catalog_lhcl_prod_bcp.bcp_edv_fabseg.T39290_hm_adm_hip_ahlo_score') \n",
    "info = espejo_sql.filter(\"CODMES >= 202201\").groupBy(\"CODMES\").agg(F.count(\"*\").alias(\"REGISTROS\"), F.avg('PD_FWL_2024Q4').alias('PD')).orderBy(\"CODMES\")\n",
    "print_res(info)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7382155985443083,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "00_Extraccion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
